{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "GZPj0dnxCFrF",
    "outputId": "97b196c9-fcd8-4e33-cc98-c77cb4e64de2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-0d210b42-982f-4655-9718-c436a07f200c\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-0d210b42-982f-4655-9718-c436a07f200c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset_melspectrogram.npy to dataset_melspectrogram.npy\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6NRi1C84C2DQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(np.load(\"dataset_melspectrogram.npy\",allow_pickle= True))\n",
    "data.columns = ['feature', 'label']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = np.array(data.feature.tolist())\n",
    "y = np.array(data.label.tolist())\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,val_x,y,val_y = train_test_split(X,y)\n",
    "lb = LabelEncoder()\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "y = np_utils.to_categorical(lb.fit_transform(y))\n",
    "val_y = np_utils.to_categorical(lb.fit_transform(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYeTNd3Jcepb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "\n",
    "\n",
    "num_labels = y.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(512, input_shape=(128,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "ARdYvHEtk54C",
    "outputId": "454ce498-ece9-4b3c-b43f-4ccd10971e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 199,946\n",
      "Trainable params: 199,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2553
    },
    "colab_type": "code",
    "id": "EixAes_Hcl-A",
    "outputId": "ae9af24a-29b5-4870-c894-b199d445a782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6549 samples, validate on 2183 samples\n",
      "Epoch 1/72\n",
      "6549/6549 [==============================] - 0s 67us/step - loss: 0.7896 - acc: 0.7540 - val_loss: 0.8349 - val_acc: 0.7604\n",
      "Epoch 2/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.7903 - acc: 0.7528 - val_loss: 0.8169 - val_acc: 0.7645\n",
      "Epoch 3/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.7718 - acc: 0.7619 - val_loss: 0.8085 - val_acc: 0.7609\n",
      "Epoch 4/72\n",
      "6549/6549 [==============================] - 0s 59us/step - loss: 0.8004 - acc: 0.7577 - val_loss: 0.7944 - val_acc: 0.7687\n",
      "Epoch 5/72\n",
      "6549/6549 [==============================] - 0s 60us/step - loss: 0.7847 - acc: 0.7569 - val_loss: 0.8322 - val_acc: 0.7563\n",
      "Epoch 6/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.8044 - acc: 0.7528 - val_loss: 0.8074 - val_acc: 0.7673\n",
      "Epoch 7/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.7767 - acc: 0.7557 - val_loss: 0.8146 - val_acc: 0.7705\n",
      "Epoch 8/72\n",
      "6549/6549 [==============================] - 0s 65us/step - loss: 0.7842 - acc: 0.7551 - val_loss: 0.7666 - val_acc: 0.7806\n",
      "Epoch 9/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.7742 - acc: 0.7642 - val_loss: 0.8078 - val_acc: 0.7719\n",
      "Epoch 10/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.7627 - acc: 0.7662 - val_loss: 0.7955 - val_acc: 0.7696\n",
      "Epoch 11/72\n",
      "6549/6549 [==============================] - 0s 66us/step - loss: 0.7571 - acc: 0.7618 - val_loss: 0.8057 - val_acc: 0.7806\n",
      "Epoch 12/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.7424 - acc: 0.7707 - val_loss: 0.7980 - val_acc: 0.7746\n",
      "Epoch 13/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.7582 - acc: 0.7658 - val_loss: 0.7902 - val_acc: 0.7714\n",
      "Epoch 14/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.7353 - acc: 0.7734 - val_loss: 0.7820 - val_acc: 0.7801\n",
      "Epoch 15/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.7505 - acc: 0.7707 - val_loss: 0.8073 - val_acc: 0.7792\n",
      "Epoch 16/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.7578 - acc: 0.7673 - val_loss: 0.7820 - val_acc: 0.7751\n",
      "Epoch 17/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.7249 - acc: 0.7765 - val_loss: 0.7823 - val_acc: 0.7815\n",
      "Epoch 18/72\n",
      "6549/6549 [==============================] - 0s 65us/step - loss: 0.7053 - acc: 0.7813 - val_loss: 0.7765 - val_acc: 0.7874\n",
      "Epoch 19/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.7209 - acc: 0.7768 - val_loss: 0.7777 - val_acc: 0.7755\n",
      "Epoch 20/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.7463 - acc: 0.7749 - val_loss: 0.7959 - val_acc: 0.7792\n",
      "Epoch 21/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.7239 - acc: 0.7798 - val_loss: 0.7695 - val_acc: 0.7728\n",
      "Epoch 22/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6930 - acc: 0.7816 - val_loss: 0.7889 - val_acc: 0.7732\n",
      "Epoch 23/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.7689 - acc: 0.7678 - val_loss: 0.7666 - val_acc: 0.7888\n",
      "Epoch 24/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.7187 - acc: 0.7800 - val_loss: 0.7888 - val_acc: 0.7893\n",
      "Epoch 25/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.7108 - acc: 0.7757 - val_loss: 0.7706 - val_acc: 0.7838\n",
      "Epoch 26/72\n",
      "6549/6549 [==============================] - 0s 66us/step - loss: 0.7288 - acc: 0.7755 - val_loss: 0.7602 - val_acc: 0.7801\n",
      "Epoch 27/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.6888 - acc: 0.7824 - val_loss: 0.7481 - val_acc: 0.7879\n",
      "Epoch 28/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6937 - acc: 0.7887 - val_loss: 0.7782 - val_acc: 0.7879\n",
      "Epoch 29/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.7242 - acc: 0.7853 - val_loss: 0.7807 - val_acc: 0.7842\n",
      "Epoch 30/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.7181 - acc: 0.7847 - val_loss: 0.7648 - val_acc: 0.7884\n",
      "Epoch 31/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.7095 - acc: 0.7829 - val_loss: 0.7816 - val_acc: 0.7838\n",
      "Epoch 32/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.7297 - acc: 0.7836 - val_loss: 0.7639 - val_acc: 0.7874\n",
      "Epoch 33/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.7302 - acc: 0.7803 - val_loss: 0.7883 - val_acc: 0.7842\n",
      "Epoch 34/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.7037 - acc: 0.7861 - val_loss: 0.7558 - val_acc: 0.7829\n",
      "Epoch 35/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6855 - acc: 0.7939 - val_loss: 0.7384 - val_acc: 0.7879\n",
      "Epoch 36/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.6737 - acc: 0.7945 - val_loss: 0.7607 - val_acc: 0.7870\n",
      "Epoch 37/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6952 - acc: 0.7923 - val_loss: 0.7805 - val_acc: 0.7943\n",
      "Epoch 38/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6805 - acc: 0.7994 - val_loss: 0.7937 - val_acc: 0.7824\n",
      "Epoch 39/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.6899 - acc: 0.7916 - val_loss: 0.7836 - val_acc: 0.7861\n",
      "Epoch 40/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6833 - acc: 0.7995 - val_loss: 0.7671 - val_acc: 0.7962\n",
      "Epoch 41/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.6897 - acc: 0.7951 - val_loss: 0.7875 - val_acc: 0.7916\n",
      "Epoch 42/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6631 - acc: 0.7986 - val_loss: 0.7933 - val_acc: 0.7856\n",
      "Epoch 43/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6874 - acc: 0.7893 - val_loss: 0.7475 - val_acc: 0.7861\n",
      "Epoch 44/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6967 - acc: 0.7948 - val_loss: 0.7668 - val_acc: 0.7943\n",
      "Epoch 45/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6855 - acc: 0.7980 - val_loss: 0.7460 - val_acc: 0.7948\n",
      "Epoch 46/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6234 - acc: 0.8099 - val_loss: 0.7341 - val_acc: 0.8049\n",
      "Epoch 47/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6798 - acc: 0.7978 - val_loss: 0.7537 - val_acc: 0.7962\n",
      "Epoch 48/72\n",
      "6549/6549 [==============================] - 0s 63us/step - loss: 0.6871 - acc: 0.7936 - val_loss: 0.7652 - val_acc: 0.7962\n",
      "Epoch 49/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6668 - acc: 0.8026 - val_loss: 0.7784 - val_acc: 0.7870\n",
      "Epoch 50/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6806 - acc: 0.7962 - val_loss: 0.7602 - val_acc: 0.7984\n",
      "Epoch 51/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6432 - acc: 0.8000 - val_loss: 0.7692 - val_acc: 0.7943\n",
      "Epoch 52/72\n",
      "6549/6549 [==============================] - 0s 65us/step - loss: 0.6425 - acc: 0.8039 - val_loss: 0.7589 - val_acc: 0.7911\n",
      "Epoch 53/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6381 - acc: 0.8094 - val_loss: 0.7602 - val_acc: 0.7952\n",
      "Epoch 54/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6194 - acc: 0.8122 - val_loss: 0.7061 - val_acc: 0.8094\n",
      "Epoch 55/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6143 - acc: 0.8076 - val_loss: 0.7203 - val_acc: 0.8012\n",
      "Epoch 56/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6476 - acc: 0.8088 - val_loss: 0.7413 - val_acc: 0.8035\n",
      "Epoch 57/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6433 - acc: 0.8065 - val_loss: 0.7195 - val_acc: 0.8085\n",
      "Epoch 58/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6473 - acc: 0.8088 - val_loss: 0.7606 - val_acc: 0.8012\n",
      "Epoch 59/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6690 - acc: 0.8076 - val_loss: 0.7518 - val_acc: 0.8126\n",
      "Epoch 60/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6338 - acc: 0.8052 - val_loss: 0.7339 - val_acc: 0.8030\n",
      "Epoch 61/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.5820 - acc: 0.8200 - val_loss: 0.7386 - val_acc: 0.8090\n",
      "Epoch 62/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6122 - acc: 0.8165 - val_loss: 0.7641 - val_acc: 0.8076\n",
      "Epoch 63/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6163 - acc: 0.8120 - val_loss: 0.7441 - val_acc: 0.8108\n",
      "Epoch 64/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6065 - acc: 0.8148 - val_loss: 0.7670 - val_acc: 0.8081\n",
      "Epoch 65/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6139 - acc: 0.8134 - val_loss: 0.7543 - val_acc: 0.8085\n",
      "Epoch 66/72\n",
      "6549/6549 [==============================] - 0s 64us/step - loss: 0.6692 - acc: 0.7989 - val_loss: 0.7367 - val_acc: 0.8085\n",
      "Epoch 67/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.6671 - acc: 0.8075 - val_loss: 0.7177 - val_acc: 0.8090\n",
      "Epoch 68/72\n",
      "6549/6549 [==============================] - 0s 65us/step - loss: 0.6343 - acc: 0.8154 - val_loss: 0.7105 - val_acc: 0.8076\n",
      "Epoch 69/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6419 - acc: 0.8079 - val_loss: 0.7309 - val_acc: 0.8108\n",
      "Epoch 70/72\n",
      "6549/6549 [==============================] - 0s 62us/step - loss: 0.5922 - acc: 0.8201 - val_loss: 0.7265 - val_acc: 0.8081\n",
      "Epoch 71/72\n",
      "6549/6549 [==============================] - 0s 65us/step - loss: 0.5950 - acc: 0.8142 - val_loss: 0.7329 - val_acc: 0.8012\n",
      "Epoch 72/72\n",
      "6549/6549 [==============================] - 0s 61us/step - loss: 0.6129 - acc: 0.8212 - val_loss: 0.7182 - val_acc: 0.8122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc04fb16ac8>"
      ]
     },
     "execution_count": 183,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=64, epochs=72, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real voice for Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPBB7VWQiE5i"
   },
   "outputs": [],
   "source": [
    "t = np.array(([[1.15493136e+00, 2.10298052e-01, 1.05901701e-01, 1.03373285e-01,\n",
    "       1.59867378e-01, 1.12249504e-01, 1.36739965e-01, 9.98120482e-02,\n",
    "       1.15319728e-01, 9.83339840e-02, 9.16686853e-02, 1.19656299e-01,\n",
    "       1.59758105e-01, 1.67325443e-01, 1.86402600e-01, 2.12975184e-01,\n",
    "       2.31010683e-01, 2.63181930e-01, 2.63148158e-01, 2.84946574e-01,\n",
    "       2.28883849e-01, 2.68223562e-01, 3.30641298e-01, 3.08460060e-01,\n",
    "       3.13056225e-01, 2.73003325e-01, 2.42380935e-01, 2.24883289e-01,\n",
    "       1.94566200e-01, 2.00358464e-01, 2.16113828e-01, 2.80035372e-01,\n",
    "       3.39006161e-01, 4.92212008e-01, 3.48604073e-01, 1.71719988e-01,\n",
    "       1.64796059e-01, 1.79469613e-01, 1.47117126e-01, 1.74012518e-01,\n",
    "       1.92526171e-01, 1.70098030e-01, 1.39364421e-01, 1.42388308e-01,\n",
    "       1.59197231e-01, 1.20166959e-01, 1.12824481e-01, 1.17615444e-01,\n",
    "       9.99552547e-02, 9.03600785e-02, 6.95672167e-02, 6.35501180e-02,\n",
    "       5.11677198e-02, 5.41690983e-02, 6.01481503e-02, 5.97929026e-02,\n",
    "       5.27991220e-02, 4.97274766e-02, 4.86544909e-02, 4.94390188e-02,\n",
    "       4.41017216e-02, 3.95325518e-02, 4.01408952e-02, 4.07945929e-02,\n",
    "       4.36251268e-02, 5.77484790e-02, 5.23161590e-02, 5.30011481e-02,\n",
    "       4.48174342e-02, 5.74205155e-02, 5.16235435e-02, 2.70089011e-02,\n",
    "       2.17748558e-02, 2.35853489e-02, 1.80708654e-02, 1.49908225e-02,\n",
    "       1.39364564e-02, 1.13363997e-02, 1.12072589e-02, 1.30633108e-02,\n",
    "       1.23835278e-02, 1.18411097e-02, 1.18238301e-02, 1.05835251e-02,\n",
    "       1.24288570e-02, 1.24108279e-02, 1.13383377e-02, 1.17887514e-02,\n",
    "       1.13309365e-02, 1.08556195e-02, 9.51523169e-03, 8.61057111e-03,\n",
    "       8.59713014e-03, 9.11368410e-03, 8.91576623e-03, 8.43364419e-03,\n",
    "       6.84650706e-03, 6.28971977e-03, 5.31512221e-03, 4.56287185e-03,\n",
    "       4.01436960e-03, 3.76829297e-03, 3.06528732e-03, 2.70297262e-03,\n",
    "       2.35203755e-03, 2.08847257e-03, 1.84738122e-03, 1.66534314e-03,\n",
    "       1.51928040e-03, 1.45878618e-03, 1.34530812e-03, 1.29033217e-03,\n",
    "       1.25068392e-03, 1.28685984e-03, 1.32355408e-03, 1.29465312e-03,\n",
    "       1.27020425e-03, 1.22639119e-03, 1.13234835e-03, 9.30905191e-04,\n",
    "       7.25273156e-04, 5.30564969e-04, 3.27436367e-04, 1.60595047e-04,\n",
    "       5.77387158e-05, 1.52281969e-05, 2.61043829e-06, 2.46439030e-07]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6uLqQpVjpYSC",
    "outputId": "c5882d27-4dd4-450d-c995-fa59f8536d78"
   },
   "source": [
    "###### it predicted right a real world sound\n",
    "http://soundbible.com/460-Children-Playing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6uLqQpVjpYSC",
    "outputId": "c5882d27-4dd4-450d-c995-fa59f8536d78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 204,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(t)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8M_7fEdXm10"
   },
   "source": [
    "**Implementing XGBOOST Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZkY89khHeF6"
   },
   "outputs": [],
   "source": [
    "train = np.argmax(y,axis =  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qerr71D_PTGo"
   },
   "outputs": [],
   "source": [
    "test = np.argmax(val_y,axis =  1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VjuVar87PcJ3",
    "outputId": "028c192c-93a3-4f86-b1a8-bfd1876521de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6549, 128)"
      ]
     },
     "execution_count": 207,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =X\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdQoky2iPe1c"
   },
   "outputs": [],
   "source": [
    "test_x = val_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x533HxHrPknX"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbPVx1WcTY_J"
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(learning_rate =0.1, \n",
    "                      n_estimators=280, \n",
    "                      max_depth=5,\n",
    "                      min_child_weight=1, \n",
    "                      gamma=0, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=0.8,\n",
    "                      objective= 'binary:logistic', \n",
    "                      nthread=4, \n",
    "                      scale_pos_weight=1, \n",
    "                      seed=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "W87KEg2JWJrA",
    "outputId": "469d5c5b-ccef-4ab6-f42b-bfe670ade1f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=280, n_jobs=1,\n",
       "              nthread=4, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=60,\n",
       "              silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 211,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFOGDEl8WOOl"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MSmDFba8W86H",
    "outputId": "0bfede6b-202e-4eeb-f907-a67b40ee84f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2, ..., 8, 7, 0])"
      ]
     },
     "execution_count": 213,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rHM2mAeXXLz-",
    "outputId": "d1772228-b93b-4c71-db8e-df27b4ac2e68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2, ..., 8, 7, 0])"
      ]
     },
     "execution_count": 214,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jiFkngsuXNb-",
    "outputId": "f58e91de-35d7-4f10-e8ce-03838636c091"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8850206138341732"
      ]
     },
     "execution_count": 215,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as met\n",
    "met.accuracy_score(test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "pBa05cMZXZvG",
    "outputId": "bb0c1031-6ac0-435c-c369-1ca36ff41fa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[237,   0,   3,   0,   1,   0,   0,   1,   0,   1],\n",
       "       [  1,  84,   2,   5,   3,   0,   1,   1,   0,   7],\n",
       "       [  2,   0, 226,   6,   8,   2,   1,   1,   2,  15],\n",
       "       [  5,   1,  22, 213,   5,   0,   2,   1,  10,  15],\n",
       "       [  1,   0,   7,   3, 220,   0,   0,   8,   1,   5],\n",
       "       [  1,   1,   7,   0,   0, 245,   1,   0,   2,   1],\n",
       "       [  1,   0,   6,   2,   6,   1,  73,   4,   0,   2],\n",
       "       [  1,   0,   0,   0,   7,   0,   1, 217,   0,   3],\n",
       "       [  0,   0,   5,   1,   0,   0,   0,   2, 221,   5],\n",
       "       [  3,   1,  22,   6,   3,   0,   2,   3,   2, 196]])"
      ]
     },
     "execution_count": 216,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met.confusion_matrix(test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aikv-HFZXfYU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iv52hFh4rqvE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Model_MelSpectrogram.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
